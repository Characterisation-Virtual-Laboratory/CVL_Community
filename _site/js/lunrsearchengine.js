
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/CVL_Community/404.html",
    "title": "404",
    "body": "404 Page does not exist!: Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/CVL_Community/about",
    "title": "About the Characterisation Virtual Laboratory Community",
    "body": "   The Characterisation Virtual Laboratory Community  The Characterisation Virtual Laboratory (CVL) community is a group of researchers, university lecturers, and health professionals who engage in developing and maintaining materials for training and practice and encourage best data practices, including the use of the CVL infrastructure.   This website collects tutorials, slides, and exercises developed and  maintained by the Characterisation Virtual Laboratory community.   The Characterisation Virtual Laboratory:     The Characterisation Virtual Laboratory is a free cloud-based virtual desktop workbench to perform   analysis of complex image and microscopy data. It serves to run analyses   in a large computing infrastructure, all embedded in a web browser   accessible using AAF (Australian Access Federation), and connected to a   HPC (high performance computing) infrastructure.   For more information please visit https://cvl. org. au.   CVL Software Tools:   The available tools on the Characterisation Virtual Laboratory are listed under Software and versions documentation.   Virtual Laboratories, like the CVL, can save researchers time as they do not have to create and   maintain their own online environments and software tools.   Virtual Desktop:   Currently the virtual desktop service is provided as a national resource by MASSIVE Multi-Modal Australian Sciences Imaging and Visualisation Environment.    A new deployment of the CVL in Queensland provided by QRISCloud is currently being tested and will become available in next months. Read more about the RCC deployment of the CVL here.   Sign in to CVL:   You can create accounts to use the CVL either in the MASSIVE infrastructure as a national resource, or test the CVL at QRISCloud following these instructions.    Storage:   CVL supports extensions of MyTardis data management platform to support instrument facility data, HPC storage and external storage.   Contact for General enquiries:   Email: MASSIVE helpdesk.        Thank you for your support!    Funding:    The CVL is funded by ARDC and supported by MASSIVE in partnership with Monash University, Microscopy Australia, ANSTO, NIF, and the universities of Sydney, Queensland, Western Australia and Wollongong. As a national resource we welcome users of other institutions who will benefit from using the CVL.    "
    }, {
    "id": 2,
    "url": "http://localhost:4000/CVL_Community/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/CVL_Community/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                                                   Automating neuroimaging analysis workflows with Nipype, Arcana and Banana                              :               Last updated 28 August 2019 Hands-on workshop Date: 15 November, 2019 (after the VBIC Annual Network Meeting) Duration: 1 day (9:30 - 5:00) Proposed Location:. . . :                                                                                                                                                                       Paula Andrea Martinez                                20 Aug 2019                                                                                                                                                                                        All resources:                                                                                                     UQ Showcase FAIR discussion              :       The UQ Research Showcase was a University event held on 20 Sept, 2019. Last updated 27 Sept 2019 Introduction The National Image Facility’s Center for Advanced Imaging node at the. . . :                                                                               Paula Andrea Martinez                20 Sep 2019                                                                                                                                    FIJI intro workshop              :       CMM introduction to FIJI Last updated 5 September 2019 Registration page Location: Duhig Tower level 5 Thanks for registering for the FIJI intro workshop. This is part of the Characterisation. . . :                                                                               Paula Andrea Martinez                05 Sep 2019                                                                                                                                    Travel scholarships              :       Travel scholarships for researchers in Australia, working with complex image analysis (characterisation). Travel scholarships To help you attend a workshop the CDEVL project (Characterisation Data Enhanced Virtual Laboratory) is organising. . . :                                                                               Paula Andrea Martinez                28 Aug 2019                                                                                            Python              :       Last updated 28 August 2019 Hands-on workshop Date: , 2019 Duration: 1 day (9:30 - 5:00) Proposed Location: TBA Instructor: This is an invitation for a hands on workshop, travel. . . :                               28 Aug 2019        &lt;/span&gt;                                                                                                                            Automating neuroimaging analysis workflows with Nipype, Arcana and Banana              :       Last updated 28 August 2019 Hands-on workshop Date: 15 November, 2019 (after the VBIC Annual Network Meeting) Duration: 1 day (9:30 - 5:00) Proposed Location: Melbourne, TBA Instructor: Thomas Close. . . :                                                                               Paula Andrea Martinez                20 Aug 2019                                                                                                                                    Introduction to FreeSurfer              :       Last updated 22 July 2019 Cortical Reconstruction Process using FreeSurfer and the CVL. This workshop was requested by Sydney Imaging in collaboration with University of Sydney as a CVL partner. . . . :                                                                               Paula Andrea Martinez                17 Jul 2019                                               &laquo; Prev       1        2        3      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/CVL_Community/js/lunrsearchengine.js",
    "title": "",
    "body": "{% assign counter = 0 %}var documents = [{% for page in site. pages %}{% if page. url contains ‘. xml’ or page. url contains ‘assets’ or page. url contains ‘category’ or page. url contains ‘tag’ %}{% else %}{  “id”: {{ counter }},  “url”: “{{ site. url }}{{site. baseurl}}{{ page. url }}”,  “title”: “{{ page. title }}”,  “body”: “{{ page. content | markdownify | replace: ‘. ’, ‘. ‘ | replace: ‘&lt;/h2&gt;’, ‘: ‘ | replace: ‘&lt;/h3&gt;’, ‘: ‘ | replace: ‘&lt;/h4&gt;’, ‘: ‘ | replace: ‘&lt;/p&gt;’, ‘ ‘ | strip_html | strip_newlines | replace: ‘ ‘, ‘ ‘ | replace: ‘”’, ‘ ‘ }}”{% assign counter = counter | plus: 1 %}  }, {% endif %}{% endfor %}{% for page in site. without-plugin %}{  “id”: {{ counter }},  “url”: “{{ site. url }}{{site. baseurl}}{{ page. url }}”,  “title”: “{{ page. title }}”,  “body”: “{{ page. content | markdownify | replace: ‘. ’, ‘. ‘ | replace: ‘&lt;/h2&gt;’, ‘: ‘ | replace: ‘&lt;/h3&gt;’, ‘: ‘ | replace: ‘&lt;/h4&gt;’, ‘: ‘ | replace: ‘&lt;/p&gt;’, ‘ ‘ | strip_html | strip_newlines | replace: ‘ ‘, ‘ ‘ | replace: ‘”’, ‘ ‘ }}”{% assign counter = counter | plus: 1 %}  }, {% endfor %}{% for page in site. posts %}{  “id”: {{ counter }},  “url”: “{{ site. url }}{{site. baseurl}}{{ page. url }}”,  “title”: “{{ page. title }}”,  “body”: “{{ page. date | date: “%Y/%m/%d” }} - {{ page. content | markdownify | replace: ‘. ’, ‘. ‘ | replace: ‘&lt;/h2&gt;’, ‘: ‘ | replace: ‘&lt;/h3&gt;’, ‘: ‘ | replace: ‘&lt;/h4&gt;’, ‘: ‘ | replace: ‘&lt;/p&gt;’, ‘ ‘ | strip_html | strip_newlines | replace: ‘ ‘, ‘ ‘ | replace: ‘”’, ‘ ‘ }}”{% assign counter = counter | plus: 1 %}  }{% if forloop. last %}{% else %}, {% endif %}{% endfor %}]; var idx = lunr(function () {  this. ref(‘id’)  this. field(‘title’)  this. field(‘body’) 123456789101112131415161718192021222324documents. forEach(function (doc) {  this. add(doc)}, this) }); function lunr_search(term) {document. getElementById('lunrsearchresults'). innerHTML = '&lt;ul&gt;&lt;/ul&gt;';if(term) {  document. getElementById('lunrsearchresults'). innerHTML =  &lt;p&gt;Search results for '  + term +  '&lt;/p&gt;  + document. getElementById('lunrsearchresults'). innerHTML;  //put results on the screen.   var results = idx. search(term);  if(results. length&gt;0){    //console. log(idx. search(term));    //if results    for (var i = 0; i &lt; results. length; i++) {      // more statements      var ref = results[i]['ref'];      var url = documents[ref]['url'];      var title = documents[ref]['title'];      var body = documents[ref]['body']. substring(0,160)+'. . . ';      document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML = document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML +  &lt;li class='lunrsearchresult'&gt;&lt;a href='  + url +  '&gt;&lt;span class='title'&gt;  + title +  &lt;/span&gt;&lt;br /&gt;&lt;span class='body'&gt; + body + &lt;/span&gt;&lt;br /&gt;&lt;span class='url'&gt; + url + &lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ;    }  } else {    document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML =  &lt;li class='lunrsearchresult'&gt;No results found. . . &lt;/li&gt; ;  }}return false; }function lunr_search(term) {  $(‘#lunrsearchresults’). show( 400 );  $( “body” ). addClass( “modal-open” ); 123456789101112131415161718192021document. getElementById('lunrsearchresults'). innerHTML = '&lt;div id= resultsmodal  class= modal fade show d-block  tabindex= -1  role= dialog  aria-labelledby= resultsmodal &gt; &lt;div class= modal-dialog shadow-lg  role= document &gt; &lt;div class= modal-content &gt; &lt;div class= modal-header  id= modtit &gt; &lt;button type= button  class= close  id= btnx  data-dismiss= modal  aria-label= Close &gt; &amp;times; &lt;/button&gt; &lt;/div&gt; &lt;div class= modal-body &gt; &lt;ul class= mb-0 &gt; &lt;/ul&gt;  &lt;/div&gt; &lt;div class= modal-footer &gt;&lt;button id= btnx  type= button  class= btn btn-danger btn-sm  data-dismiss= modal &gt;Close&lt;/button&gt;&lt;/div&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;';if(term) {  document. getElementById('modtit'). innerHTML =  &lt;h5 class='modal-title'&gt;Search results for '  + term +  '&lt;/h5&gt;  + document. getElementById('modtit'). innerHTML;  //put results on the screen.   var results = idx. search(term);  if(results. length&gt;0){    //console. log(idx. search(term));    //if results    for (var i = 0; i &lt; results. length; i++) {      // more statements      var ref = results[i]['ref'];      var url = documents[ref]['url'];      var title = documents[ref]['title'];      var body = documents[ref]['body']. substring(0,160)+'. . . ';      document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML = document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML +  &lt;li class='lunrsearchresult'&gt;&lt;a href='  + url +  '&gt;&lt;span class='title'&gt;  + title +  &lt;/span&gt;&lt;br /&gt;&lt;small&gt;&lt;span class='body'&gt; + body + &lt;/span&gt;&lt;br /&gt;&lt;span class='url'&gt; + url + &lt;/span&gt;&lt;/small&gt;&lt;/a&gt;&lt;/li&gt; ;    }  } else {    document. querySelectorAll('#lunrsearchresults ul')[0]. innerHTML =  &lt;li class='lunrsearchresult'&gt;Sorry, no results found. Close &amp; try a different search!&lt;/li&gt; ;  }}return false; }$(function() {  $(“#lunrsearchresults”). on(‘click’, ‘#btnx’, function () {    $(‘#lunrsearchresults’). hide( 5 );    $( “body” ). removeClass( “modal-open” );  });}); "
    }, {
    "id": 5,
    "url": "http://localhost:4000/CVL_Community/css/main.css",
    "title": "",
    "body": "/* We need to add display:inline in order to align the ‘»’ of the ‘read more’ link */. post-excerpt p {	display:inline;} // Import partials from sass_dir (defaults to _sass)@import	“syntax”,  “starsnonscss”; "
    }, {
    "id": 6,
    "url": "http://localhost:4000/CVL_Community/images/",
    "title": "",
    "body": "Source of Imageshttps://free-images. com marked as Public Domain or CC0 and is free to use "
    }, {
    "id": 7,
    "url": "http://localhost:4000/CVL_Community/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 8,
    "url": "http://localhost:4000/CVL_Community/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All resources:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 9,
    "url": "http://localhost:4000/CVL_Community/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All resources:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 10,
    "url": "http://localhost:4000/CVL_Community/FAIR-UQ/",
    "title": "UQ Showcase FAIR discussion",
    "body": "2019/09/20 - The UQ Research Showcase was a University event held on 20 Sept, 2019. Last updated 27 Sept 2019 IntroductionThe National Image Facility’s Center for Advanced Imaging node at the University of Queensland was part of the UQ Research Showcase. We joined the event by providing two workshops for the community to discuss about FAIR for data and software. Workshop agenda: Each workshop went for about 1 hour.  Welcome and Intro (5min) Let’s explain FAIR (15min) Group discussion (40min)Materials and resources: Have a look at the slides. Suggested Resources:  Go FAIR principles https://www. go-fair. org/fair-principles/ FAIRsharing standards https://fairsharing. org/standards/ Top 10 FAIR domain specific guides https://doi. org/10. 5281/zenodo. 3409968 and website.  How FAIR is your data checklist http://doi. org/10. 5281/zenodo. 1065991.  List of references related to FAIRWho to reach for questions?:  Paula Andrea Martinez / Characterisation Training Coordinator - National Image Facility / p. martinez at uq. edu. "
    }, {
    "id": 11,
    "url": "http://localhost:4000/CVL_Community/FIJIintro/",
    "title": "FIJI intro workshop",
    "body": "2019/09/05 - CMM introduction to FIJILast updated 5 September 2019 Registration page Location: Duhig Tower level 5 Thanks for registering for the FIJI intro workshop. This is part of the Characterisation Data Enhanced project with the aim of building national awareness of data management and analysis capability and capacity. We aim to use this space to answer your especific questions about data analysis in microscopy using FIJI and offer you tools to do so. We will try as best as possible to cover the basics. If you are looking for more advaced ways to use FIJI as analysis tool, please refer to the CVL community website for a list of online tutorials, which includes a link to Cameron’s FIJI user manual. Using FIJI during the workshop:  Make sure to bring your laptop with FIJI installed or have accessed the CVL, once before.  You can download sample data provided by Matthias, if you are using your own laptop.  We would ask you to kindly work in pairs with anyone who is not able to bring a laptop or who did not request a CVL account before hand.  If you are using the CVL at awoonga we highly recommend you to become familiar with the Awoonga user guide and ask questions if you need. Instructor:  Cameron Novell from Monash UniversityMaterials:  FIJI manual by Cameron Nowell and images.  Sample data provided by Matthias Floetenmeyer (already available through the CVL @ awoonga) at ` /sw7/CVL/training/CMM_Sample_Training_data/`Characterisation Virtual Laboratory (CVL): Nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freely and cloud-ready. The CVL is also a community who support each other in training and best practices. Using CVL at Awoonga: Each Awoonga user is allocated a directory on the /30days file system. It is present on the Awoonga login nodes and the Awoonga compute nodes. The main purpose is to hold large data sets on a temporary basis while you are computing against them. It is designed to be a data staging area. Create a project directory in this folder for analysis, and read more about it Awoonga user guide. At the end of the workshop: Please fill in the anonymous feedback form before leaving. "
    }, {
    "id": 12,
    "url": "http://localhost:4000/CVL_Community/scholarships/",
    "title": "Travel scholarships",
    "body": "2019/08/28 - Travel scholarships for researchers in Australia, working with complex image analysis (characterisation). Travel scholarshipsTo help you attend a workshop the CDEVL project (Characterisation Data Enhanced Virtual Laboratory) is organising travel scholarships which will cover the cost of travel (airfare, train, bus,taxi, accommodation). These are provided up to specified caps as follows:  up to A$500 for participants coming from a state other than where the workshop is being held.  up to A$800 for participants coming from WA or NT. Application: Researchers in Australia, working with complex image analysis (characterisation) may apply for a travel scholarship (at least 3 weeks before the event) by answering the following questions:  Name and date of the workshop Brief research domain, career level, institution What is your motivation for attending this workshop? Brief reasons why your institution cannot fund your attendance How your attendance will make a difference to your career? Commit to share your experience after the workshop,for example, a video or short story (a month after the workshop) or instruct or facilitate a workshop (in the following 6 months). Please email your application as soon as possible. Selection: The organisers will select the recipients of all scholarhsip applicants as they come and will close to review 3 weeks before the event. Selection is based on your current work or study, location, your motivation for applying, the reasons for needing financial support and the impact this event will have on your career. Incomplete applications won’t be assessed. Results: Results will be announced approximately 3 weeks before the event start date, however for some events this may be delayed. Selection results do not impact your admission to the workshop. You will be contacted to organise your travel, and we will pay for your travel costs in advance. In the ocasion that you would like to organise your travel costs we can offer reimbursments with the cap above and you will be required to fill a reimbursement form and send original receipts from travel costs. "
    }, {
    "id": 13,
    "url": "http://localhost:4000/CVL_Community/python/",
    "title": "Python",
    "body": "2019/08/28 - Last updated 28 August 2019 Hands-on workshopDate: , 2019Duration: 1 day (9:30 - 5:00)Proposed Location: TBAInstructor: This is an invitation for a hands on workshop, travel scholarships are available. If you would like more information about this, please get in touch. DescriptionThis course is meant to be an introduction to the Python programming language using data types familiar to neuroscience students or academics. Emphasis will be on introducing concepts of visualisation, data manipulation and analysis using Python packages Numpy, Pandas, Matplotlib and Nipype. Day 4 https://github. com/dasaderi/python_neurobootcamp/tree/master/day-4 Goals:  Encourage interoperability and collaboration between developers of Python programs Expose neuroscientists to the Python-based tools now available.    Registration link.  Travel scholarships are available, follow the link for instructions on how to apply. Pre-requisites:  A laptop with a web browser and either of the following options:     Anaconda and Nipype pre installed instructions   NeuroDebian pre installed instructions   An account on MASSIVE/CVL instructions   Details:  Freely available datasets will be used for this workshop.  Date: , 2019 Duration: 1 day (9:30 - 5:00) Location: Instructor: Registration link. Why Python for Neuroscience?: We invite you to read the following resources  Python in neuroscience Teaching Python to Neuroscience students Object-Oriented Programming in Python Using containers in sciencehttps://www. frontiersin. org/articles/10. 3389/fninf. 2011. 00013/fullNipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python https://nipy. org/https://github. com/kylerbrown/python-for-neurosciencehttp://brainsuite. org/nipype-interactive-tutorial/https://www. frontiersin. org/articles/10. 3389/fninf. 2011. 00013/fullhttp://brainsuite. org/nipype-interactive-tutorial/ Characterisation Virtual Laboratory (CVL): The CVL is a nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freelyand cloud-ready. The CVL is also a community who support trainingand best data management practices. "
    }, {
    "id": 14,
    "url": "http://localhost:4000/CVL_Community/workflows_proposal/",
    "title": "Automating neuroimaging analysis workflows with Nipype, Arcana and Banana",
    "body": "2019/08/20 - Last updated 28 August 2019 Hands-on workshopDate: 15 November, 2019 (after the VBIC Annual Network Meeting)Duration: 1 day (9:30 - 5:00)Proposed Location: Melbourne, TBAInstructor: Thomas Close from Monash Biomedical Imaging This is an invitation for a hands on workshop, travel scholarships are available (apply before Oct 4th). If you would like more information about this, please get in touch. Automating neuroimaging analysis workflows with Nipype, Arcana and BananaAnalysis of neuroimaging-research data involves the sequential application of algorithms implemented in a number of heterogeneous toolkits (e. g. FSL, SPM, MRTrix, ANTs, AFNI, DiPy). This makes constructing complete workflows challenging as it requires not only the relevant scientific knowledge but also familiarity with the syntax and options of each of the tools involved. The workshop will show how to wrap neuroimaging tools within consistent interfaces and link them together into robust workflows using the Nipype Python package. Participants will then be shown how common components of these analysis workflows can be consolidated within object-oriented base classes using the Abstraction of Repository Centric ANAlysis (Arcana) (http://arcana. readthedocs. io) framework, and how this is used in the Brain imAgiNg Analysis iN Arcana (Banana) package to capture the arcana (obscure knowledge) of neuroimaging analysis workflow design. In the last part of the course, participants will learn how to extend and customise the classes in Banana to the specific needs of their own analysis, and apply these workflows to project data stored in BIDS datasets. Then finally, how workflows can be automated for data stored in XNAT repositories by encapsulating them within Docker containers and using XNAT’s “container service”.    Registration link.  Travel scholarships are available, apply before Oct 4th, follow the link for instructions on how to apply. Pre-requisites:  Proficiency in Python programming, or programming in general and familiarity with object-oriented concepts.  A conceptual understanding of container technology (i. e. Docker/Singularity) would be beneficial.  Some familiarity with the function of standard neuroimaging toolkits (e. g. FSL, SPM, MRTrix, ANTs, AFNI, DiPy) would be good but not strictly necessary.  An account on MASSIVE/CVL. Details:  Freely available datasets will be used for this workshop.  Date: 15 November, 2019 (after the VBIC Annual Network Meeting) Duration: 1 day (9:30 - 5:00) Location: Melbourne Instructor: Thomas Close from MBI (Monash Biomedical Imaging) Registration link.  Travel scholarships are available, apply before Oct 4th for those who would need to travel to Melbourne to attend. Characterisation Virtual Laboratory (CVL): The CVL is a nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freelyand cloud-ready. The CVL is also a community who support trainingand best data management practices. "
    }, {
    "id": 15,
    "url": "http://localhost:4000/CVL_Community/FreeSurfer-CVL/",
    "title": "Introduction to FreeSurfer",
    "body": "2019/07/17 - Last updated 22 July 2019 Cortical Reconstruction Process using FreeSurfer and the CVL. This workshop wasrequested by Sydney Imaging in collaboration with University of Sydney as aCVL partner. It took place at Charles Perkins Centre on Friday, 19 Jul 2019. Introduction to FreeSurfer using the CVLWe use the CVL to get you acquainted with the concepts needed to performvarious modes of analysis and processing of MRI data. The tutorial is designedto be followed along in a terminal window, where commands can be copy/pastedinto the terminal window.       Materials kindly provided by Thomas Shaw MNeuroSc(Adv) BPsySc(Hons)   PhD Candidate   Centre for Advanced Imaging, The University of Queensland  FreeSurfer slides Hands on materials to login into the CVL and run recon-all as a job. Useful references are included at the end. Characterisation Virtual Laboratory (CVL): The CVL is a nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freelyand cloud-ready. The CVL is also a community of experts who support trainingand best data management practices. "
    }, {
    "id": 16,
    "url": "http://localhost:4000/CVL_Community/FAIR-CVL/",
    "title": "Intro to FAIR for NIF",
    "body": "2019/06/18 - The NIF annual meeting is happening 18-21 June 2019. It starts with a FAIRtraining event, and on boarding participants to use the CVL desktop. Last updated 17 June 2019 Introduction to FAIR dataThe National Image Facility annual meeting is happening on 18-21 June 2019 inBrisbane. This meeting starts with a FAIR training event, and on boardingparticipants to use the CVL desktop. Characterisation Virtual Laboratory (CVL): The CVL is a nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freelyand cloud-ready. The CVL is also a community of experts who support trainingand best data management practices. Workshop preparation: In preparation for the NIF workshop introduction to FAIR, pleasethink about the following questions.  What’s the approach of handling sensitive data? Is there a procedure? Linksare useful, or a simple description.  Persistent identifiers, any special PIDs that are used by NIF? apart fromDOIs or maybe RAiDs? Are there any special controlled vocabularies to describe metadata? Do you know of any recommendations from journals that you use about where tostore data? any guidelines? If people would like to share data what type of file formats are suggestedor broadly in use ? Any recommendations about license for work features?Also, please take the time to read this Nature article Make scientific data FAIR by Stall et al. , 2019 doi:10. 1038/d41586-019-01720-7 Workshop agenda: Thanks for attending this session hosted by the Characterisation VirtualLaboratory (CVL). Please complete the following feedback form before leaving tiny. cc/CVL_feedback Everything we do today is available online. You can cherry-pick what is moreimportant for you. Suggested resources will be listed at the end of eachpresentation. Find the materials for this workshop here: tiny. cc/CVL_Community under Intro to FAIR for NIF. Agenda  Introductions FAIR principles and data management What is the CVL? CVL Federation for users CVL instrument integration Q&amp;A Demo CVL at MASSIVE - If people have accounts already they can testtheir own data sets and ask questions.  Split into teams, to set up accounts for the CVLWho to reach for questions?:  Paula Andrea Martinez / Characterisation Training Coordinator - National Image Facility / p. martinez at uq. edu. au Lance Wilson / Characterisation Virtual Laboratory (CVL) Coordinator &amp;Senior HPC Consultant - Monash University Aswin Narayanan / Informatics Fellow - Centre for Advanced Imaging - National Image FacilityMaterial:  FAIR Principles and Data management The Characterisation Virtual Laboratory CVL at MASSIVE documentation http://docs. massive. org. au/After the workshop: Please fill in the anonymous feedback form before leaving: tiny. cc/CVL_feedback "
    }, {
    "id": 17,
    "url": "http://localhost:4000/CVL_Community/UQRDM-FAIR/",
    "title": "Data management and FAIR",
    "body": "2019/06/05 - CMM introduction to Data Management FAIR and UQRDMLast updated 5 June 2019 Thanks for attending this session hosted by the Characterisation Virtual Laboratory (CVL). Please complete the following feedback form before leaving https://survey. zohopublic. com/zs/ueCsAo Everything we do today is available online. It is your responsibility to select what is more important for you. Suggested resources will be listed at the end of each presentation. This is a live notepad the link is here: https://demo. codimd. org/s/SJqgnL4C4After the workshop, you can view and save this notepad with the important links and information as a PDF. Characterisation Virtual Laboratory (CVL): Nationally funded software infrastructure collaborationto make scientific tools for image analysis and processing, available freely and cloud-ready. The CVL is also a community of experts who support training and best practices. The Centre for Microscopy and Microanalysis (CMM): Is an interdisciplinary research, teaching and service centre based at The University of Queensland (UQ). CMM Actively supports and initiates microscopy &amp; microanalysis. UQ Research Data Manager (RDM): The RDM provides the UQ research community with a collaborative, safe and secure large-scale storage facility to practice good stewardship of research data. What are we going to learn?: At the end of this session you will be able to:  Create one or more UQRDM records     One of your UQRDM records will be connected to HPC collections    Reuse a set of guidelines to use HPC collections Be motivated to use data management best practices Go back to Data management recommendations Describe what the concept of FAIR means Observe how the CVL desktop worksInstructors:  Full name / email (optional) Paula Andrea Martinez / p. martinez at uq. edu. au Roger Wepf Fei YuMaterial:  The Characterisation Virtual Laboratory UQ RDM and HPC collections information relevant to only for UQ staff/Students Data Management and FAIRAfter the workshop: Please fill in the anonymous feedback form before leaving: https://survey. zohopublic. com/zs/ueCsAo "
    }, {
    "id": 18,
    "url": "http://localhost:4000/CVL_Community/IntroCryoEM/",
    "title": "CRYOZ19 workshop",
    "body": "2019/05/21 - Day 1 Starter hands-on cryo-EMMonday 3 June 2019 Intro Lectures Sample preparation &amp; cryo-TEM Hands-on sessions 3 groups Rotating sessions    Negative Staining &amp; TEM: Jeol 1400     Cryo-grids &amp; cryo-TEM: Tecnai 12     High throughput imaging: Titan &amp; Talos  Day 2 Data ProcessingTuesday 4 June 2019 Hands-on using Relion &amp; other software*  hosted on CVL &amp; MASSIVEDay 3 Data ProcessingWednesday 5 June 2019 Hands-on using Relion &amp; other software*  hosted on CVL &amp; MASSIVELectures advanced image processing: Afternoon lectures advanced image processing, these are also part of the CRYOZ19 program  Masking Helical processing Cryo EM map fitting"
    }, {
    "id": 19,
    "url": "http://localhost:4000/CVL_Community/10FAIRthings-progress/",
    "title": "Global sprint ",
    "body": "2019/05/17 - The Mozilla(moz://a) sprint idea is a month-long open opportunity for projects and communities to collaborate, hack, and learn together anytime during the month of May. Global SprintThe Mozilla(moz://a) sprint idea is a month-long open opportunity for projects and communities to collaborate, hack, and learn together anytime during the month of May. Mozilla-Library Carpentry Global Sprint, May 2019: The sprint has the aim to improve and develop Library Carpentry material. Under that umbrella we will work on the Top 10 FAIR Data &amp; Software Things. These are a number of brief guides created to help discipline-based communities understand the FAIR Principles. Register your interest on this etherpad https://pad. carpentries. org/2019-lc-mozsprint. Who is organising ?:  Mozilla Library Carpentry /The Carpentries The Australian Research Data Commons (ARDC) German National Library of Medicine (ZB MED) Many people are already involved. You are welcome to take part, either join a local hub, or work remotely. 10 FAIR things for ImagingDuring May, but specially 30-31 May, 2019 we will be working on the Top 10 FAIR things for imaging. Here is our work in progress document. We welcome contributions from diverse viewpoints and skill sets. If you contribute to this document make sure your name and details are known to us. This document is licensed under Creative Commons International Attribution license CC by 4. 0. Join the local Hub: We have booked a local hub. Room 501, level 5, building 2 (Duhig Tower),University of Queensland, Campbell Rd, St Lucia, 4067 QLD. We will start at 9:00 am AEST on the 30th of May, and work between 9:00 - 16:00, both days. Join remotely: If you are reading this information before the day. Please contact me for an intro session. On the days, please join the Gitter/Chat Room: https://gitter. im/LibraryCarpentry/Lobby. Get in contact, and collaborate in the document. Contact: You can email Paula for any questions. The simple most meaningful step you can take to collaborate is tweet (Why? Because it takes a community to nurture resources that a community wants to use and reuse). Here is a tweet example, you can add any of the links above. “The @LibCarpentry @ARDC_AU #mozsprint #lc2019 is coming back end of May (30-31). I will be working on #Top10FAIR for #imaging https://pad. carpentries. org/2019-lc-mozsprint. ” "
    }, {
    "id": 20,
    "url": "http://localhost:4000/CVL_Community/CVL-QRISCloud-get_account/",
    "title": "Sign up to CVL at QRISCloud",
    "body": "2019/05/12 - The University of Queensland’s Research Computing Centre (RCC)is building the Characterisation Virtual Laboratory (CVL)desktop to enable UQ researchers to keep data nearby andleverage a local system for imaging workloads. Getting started with CVL at QRISCloudThe process to get an account to use the CVL at QRISCloudrequires a few steps, starting with gaining access tocomputing resources. Keep in mind the CVL at QRISCloud desktopis currently in testing mode. We are testing two different options to getaccess. Your feedback is welcome. Option 1 - Step by step: The first two steps are required if you do not have an Awoonga account already.  Register for a QRIScloud Account using your institution Australia Access Federation (AAF) credentials.  Register to use the Awoonga cluster to get access to the CVL at Awoonga.  Join the CVL project. Please include a meaningful description in the form. - It takes about one day (probably less) to set your account with the right access.  Go to strudel web and select uqcvl-auth.      If asked, please login with your institutional credentials through AAF.    Click on Awoonga-SpecialQ, then Launch   A desktop will start with state checked, click Show Desktop.    Option 2 - Test auto-provision: Auto provision is similar to the steps above we are testing a logic processthat should take you automatically to the next step. The QRIScloud CVL auto-provisioning page is: https://services. qriscloud. org. au/services/cvl There are three possibilities:  QCIF members will see a “Enable QRIScloud CVL” button (which makes them a member of the CVL-Users group and/or gives them access to Awoonga, depending on which/both they do not yet have).  Non-members will see text telling them to try another location or submit a ticket to QRIScloud Support.  If they already have QRIScloud CVL (i. e. access to Awoonga and is a member of CVL-Users), they will be redirected to the CVL Workbench. Contact details: For general inquires about the CVL at QRISCloud, pleasecontact CVL at QRISCloud helpdesk. Read more about the CVL at QRISCloud: A new deployment of the CVL in Queensland provided byQRISCloud is currently being tested and will become availablein the next months. You can read more about this deployment here. Last updated on June 6, 2019. "
    }, {
    "id": 21,
    "url": "http://localhost:4000/CVL_Community/CVL-MASSIVE-get-account/",
    "title": "Sign up to CVL at MASSIVE",
    "body": "2019/05/12 - Characterisation Virtual Laboratory (CVL) desktop service isprovided as a national resource by MASSIVE (Multi-Modal Australian Sciences Imaging and Visualisation Environment). MASSIVEprovides researchers with the computing resources and tools toapply high-throughput parallel processing and deep learningtechniques to solve research questions, and allows researchersto more effectively extract knowledge from scientific data. Getting started with CVL at MASSIVEThe process to get an account to use the CVL at MASSIVErequires a few steps, starting with gaining access tocomputing resources. Keep in mind the CVL at MASSIVE desktopis currently the national resource and any Australianresearcher can apply for an account.  Log in to HPCID using your institution Australia Access Federation (AAF) credentials.  Password reset, click [Change Linux Password].  Create or join an existing project     If you are a principal investigator or a project manager please send a project request to MASSIVE by filling the following form. You will get a response in about 3 working days.    If you are a student or research assistant you need your supervisor or manager to get a project first and then give you the project code to join.     Go to strudel web (or strudel desktop) and select M3 and CVL @ MASSIVE.      If asked, please login with your institutional credentials through AAF.    Click on M3 standard Desktop, then Launch   A desktop will start with state checked, click Show Desktop.    For general inquires about the CVL at MASSIVE, please contact MASSIVE helpdesk. If you need more information and/or screenshots please visit the CVL documentation CVL accounts. What is MASSIVE?: (Multi-Modal Australian Sciences Imaging and Visualisation Environment)’s impact toscience is broad, and includes basic discoveries in thebiological, medical, computational, engineering andenvironmental sciences.  Last updated on May 14, 2019. "
    }, {
    "id": 22,
    "url": "http://localhost:4000/CVL_Community/AustralianCharacterisationFacilities/",
    "title": "Australian Characterisation Facilities",
    "body": "2019/05/04 - Characterisation refers to the general process of probing and measuring the structures and properties of materials at the micro, nano and atomic scales. The Australian Characterisation Facilities “Characterisation refers to the general process of probing and measuring the structures and properties of materials at the micro, nano and atomic scales. It is essential across natural, agricultural, physical, life and biomedical sciences and engineering. Characterisation facilities, provide researchers in Australian universities, research centres, and industries with critical infrastructure, including both instrumentation and expertise, to enable quality research outcomes in an efficient and cost-effective manner. These facilities are a key capability that underpin flagship Australian research collaborations including ARC Centres of Excellence which are both significant users and partners in the development of future characterisation techniques and applications. The Australian Characterisation community and our partners bring together thousands of researchers who are driving the future of Australian imaging and innovation”. Read more about the Collaborative Australian Characterisation Informatics Strategy here. *The Characterisation Virtual Laboratory (CVL) is operated by MASSIVE in partnership with Monash University, Microscopy Australia, ANSTO, NIF, University of Sydney, University of Queensland, University of Western Australia, and University of Wollongong. National Image Facility - NIF: Neuroscientists, imaging researchers and clinicians, platform engineers, and computational scientists. NIF nodes are 10 Universities plus ANSTO. New South Wales  University of Sydney / Brain &amp; Mind Research Institute + ANSTO University of New South Wales / The Biological Resource Imaging Laboratory (BRIL) / Imaging at Neuroscience Research Australia (NeuRA) Western Sydney University / Biomedical Magnetic Resonance Facility (BMRF) Queensland  The University of Queensland / Centre for Advanced ImagingSouth Australia  Large Animal Research &amp; Imaging FacilityVictoria  Florey Institute of Neuroscience &amp; Mental Health Monash University Swinburne University of Technology University of Melbourne / The Melbourne Brain Centre Imaging UnitWestern Australia  University of Western AustraliaAustralian Nuclear Science and Technology Organisation ANSTO:  Opal Multipurpose Reactor Australian Centre for Neutron Scattering (ACNS) The Australian Synchrotron Centre for Accelerator Sciences National Deuteration Facility National Research Cyclotron (partly NIF)Microscopy Australia: It used to be Australian Microscopy &amp; Microanalysis Research Facility (ammrf)) @GoInnerSpace  University of Sydney / University of Queensland / Centre for Microscopy and Microanalysis (CMM) University of Western Australia / Centre for Microscopy, Characterisation and Analysis (CMCA) Australian National University / Centre for Advanced Microscopy University of New South Wales / Electron Microscopy Unit SARF University of Adelaide  University of South Australia  Flinders UniversityOthers facilities:  Queensland Micro- and Nanotechnology Centre CSIRO Advanced Characterisation Facility Australian National Fabrication Facility (ANFF) / Characterisation Service National Geosequestration Laboratory (NGL)Last updated 10 June 2019. "
    }, {
    "id": 23,
    "url": "http://localhost:4000/CVL_Community/champions/",
    "title": "CVL Champions Program 2019",
    "body": "2019/05/04 - The Characterisation Virtual Laboratory (CVL) Community (Neuroscience,Microscopy, Structural Biology, Atom Probe, Neutron Techniques) is providing aunique opportunity to upskilling scientists and bioimaging professionals. The CVL Champions are a community of researchers, university lecturers, andbioimaging professionals taking part in a skills development program. Theprogram is designed to provide guidance, methods and tips for developing anddelivering quality, impactful training. With the new CVL Champions we aimto enhance the national characterisation training network and encourage the application of FAIR (Findable, Accessible, Interoperable, Reusable) data principles to research workflows. The Characterisation Virtual Laboratory is a free cloud-based virtual desktop to perform analysis of complex image and microscopy data. It is essentially a virtual computer with all the software you need pre-installed, all embedded in a web browser accessible using AAF (Australian Access Federation), and connected to a HPC (high performance computing) infrastructure to boost your analysis workflows. Read more about the CVL. 1234**TL;DR** / Summary :1. Get all costs paid to participate in a train the trainer event. 2. Form a community of engagement and maintenance of training resources. 3. Commit to deliver workshops next year, at least one of these should be using the CVL. CVL Champions Program 2019The CVL Champions Program’s aim is to create a community that stimulates network engagement across Australian characterisation facilities to raise the awareness of FAIR data principles and access to the national characterisation computing infrastructure. The CVL Champions is part of the Characterisation Data enhanced Virtual Laboratory (CDeVL) project, funded by the Australian Research Data Commons (ARDC). Invitation: The CVL Community (Neuroscience, Microscopy, Structural Biology, Atom Probe,Neutron Techniques) is providing a unique opportunity for both external andinternal staff / HRD students to develop their training skills in a 2 dayworkshop 1- 2 October (all costs paid). The workshop is designed to provideguidance, methods and tips for developing and delivering quality, impactfultraining; whilst also encouraging attendees to become reflective practitioners,able to seek and act upon feedback and try new modes of training. To join youneed to have enthusiasm for delivering knowledge to others. The training weprovide is highly interactive in nature. Throughout the workshop participantsare encouraged to bring their thoughts and voice into all discussions; sharingexperiences and swapping ideas. We will also facilitate networking betweenthe participants, regardless of their areas of expertise. If you think this workshop might be of interest to someone else, pleaseforward this opportunity. Applications close 31 July 2019. Apply here!. Why be a CVL champion?:  Becoming a CVL champion provides access to networking, advanced skills development, and demonstrates service to the profession.  The program provides the Champions with all the ready-to-use materials and knowledge required so that they can confidently re-deliver similar workshops from the Program in their own institutions.  The CVL champions are a community exemplar working together remotely and in person during two months (September/October 2019), so the time commitment is balanced.  Community members who are already involved in training can, and are encouraged to take part in the Program to improve their current teaching methodology and to further extend their network.  The program offers a two day in person meeting, with all costs paid. ApplicationWe are looking for a representative cohort of enthusiastic people, who are keen to learn and be the leaders of the national Characterisation training network. Applicants at all career stages are welcome to apply. Champions are the engine across the Australian Characterisation community to uplift data skills and specialist skills across characterisation users. We also strongly encourage members of groups that are underrepresented in science to apply. Diversity is one of our explicit evaluation criteria, and we work hard to try and make this community a comfortable and welcoming environment for all. The group of selected champions will meet in person for two days of networking and training on 1-2 October 2019, location TBA. Application timeline:  Applications open on 18 June 2019. Apply here!.  Videoconference information session on 17 July 2019. Register here.  Applications close on 31 July 2019.  Selected applicants will be contacted on 9 August 2019. Requirements:  This application is open to participants based in Australia.  Commit to attending and participating in the three programmed events, 2 online and 1 in person (see program below).  Commit to continuation of the training effort for at least until the end of 2020.  Provide at least 2 trainings sessions a year, one of which has to be part of the CVL trainings.  Promote the Characterisation Virtual Laboratory and best data management practices. * All participants will get access to the CVL infrastructure. CVL Champions agenda Remote meeting 1 (teleconference), 9 September 2019. To get to know the Champions we will allocate this time for each participant to present who they are, what they do, and their community.  Remote meeting 2 (teleconference), 23 September 2019. Champions will prepare SMART goals around the future uptake of FAIR data principles in their work activities.  In-person meeting (location TBA), 1-2 October 2019.      General introduction covering the data life cycle, the FAIR principles and a definition of data stewardship.    Evidence-based teaching practices.    Introduction to the CVL Desktop.    Stories and case studies of CVL users.    Get started preparing open access materials for the Characterisation community.     After the in person event, CVL Champions will have time to plan training activities for the coming months. CVL Champions are encouraged to self-coordinate, with the support of the Characterisation Training Coordinator.  CVL Champions are in charge of keeping all members updated about training activities, maintenance of training materials, and encouragement of best data practices for the broader community. Got questions?Please contact the Characterisation Training Coordinator. Special thanks for comments received before the publication of this post to, Noni Creasey, Ben Sinclair, Saba Salehi, and Shannon Lindsay. Last updated on 18 June 2019. "
    }, {
    "id": 24,
    "url": "http://localhost:4000/CVL_Community/Data-Management/",
    "title": "Data Management",
    "body": "2019/03/22 - Recommended data management readings. Research Data Management Ten Simple Rules for Digital Data Storage A brief illustration of the Path to a successful research project, how to get on the right track with FAIR data management.  Some Simple Guidelines for Effective Data Management of files NASA Earth Data - Data Management Good enough practices in scientific computing Nine simple ways to make it easier to (re)use your data files Recommended reading 10 HASS Data things Thing 3: Data Management planningon page 9. It includes activities and useful material about How do you make a Data Management Plan?References:  10 HASS Data things Thing 3: Data Management planning by Sara King, Nov 2018. Accessed on 20th March, 2019.  Ten simple rules for machine-actionable data management plans (preprint) by Tomasz Miksa, Stephanie Simms, Daniel Mietchen and Sarah Jones. Published on 13th Feb, 2018. Accessed on 20th March, 2019 DOI:10. 5281/zenodo. 1434938 Path to a successful research project illustration. DeiC / Deff / DTU / CBS / AAU / KU Rigsarkivet / Det Kgl Bibliotek. 2018Updated 12 June 2019 "
    }, {
    "id": 25,
    "url": "http://localhost:4000/CVL_Community/other-tutorials/",
    "title": "Publicly accessible software tutorials",
    "body": "2019/01/01 - A list of publicly accessible tutorials with a short description. We will appreciate if you can curate and/or add to this list. Last updated 5 September, 2019. Tutorials from external resourcesList of tutorials ordered alphabetically. Computational Bioimaging: From images (both light and electron microscopy) to data. This course willcover the process of dealing with microscopy data, converting between formats,analysing images in a clear and reproducible fashion and preparing images forpublication. Includes FIJI, Python and OMERO. By Matthew Hartley 2015, from JohnInnes Centre, JIC. Online tutorial. Labeled for beginners in microscopy analysis. FreeSurfer:  If you want to learn FreeSurfer the documentation is ready to be explored. FIJI:  OMERO + FIJI From GBI Sydney, Sep 2018. FIJI analysis starts on page 10. Author: Petr Walczysko part of Hands-on data management with OMERO.  ImageJ tutorials from ImageJ. net.  ImageJ tutorials using Jupyter notebooks This project contains example code for working with ImageJ and SciJava. CC0 1. 0 Universal license.  FIJI manual by Cameron Nowell and images.  Using ImageJ CC0 1. 0 Universal license.  Practical exercises to learn image analysis using ImageJ/Fiji with a strong focus on biological fluorescence microscopy data Author: Christian “Tischi” Tischer, 2018 and 2019. Suggested to look at folders handouts and practicals.  Fiji scripting tutorial using python (jython) by Albert Cardona.  ImageJ and FIJI by Peter Bankhead.  Getting started with the plugin TrackMate.  A very fast way to make tutorials in FIJI and upload them to the FIJI Wiki A brief introduction to machine learning for bio-imaging accessible to download from http://bit. do/ML-Imaging-WS provided by Nick Hamilton, Sep 2018 and March 2019.  Using FIJI with Trainable Weka from imageJ. net.  Counting neurons in brain slices with FIJI by Delane Espinueva; or two ways to count cells with ImageJ by Christine Labno. Git: Git for Scientists by Miles McBain 2019. A 3. 5 hour introduction to basic shell and git/GitHub. Read and follow along the tutorial here. This work is licensed under aCreative Commons Attribution-Share Alike 4. 0 International License. Image Data Resource:  The Image Data Resource (IDR) publishes “reference image” datasets supporting conventional peer-reviewed publications and integrates them with other imaging datasets for cross-dataset querying of metadata (e. g. genes, phenotypes, small molecules) and re-analysis. Submission of datasets to IDR and an IDR metadata example. *  MRtrix:   MRtrix documentation MRtrix discussion forum, ask questions to the community!OMERO:  OMERO it redirects to https://code. research. uts. edu. au/MIF/OMERO-instructions/wikis/homeUpdated on 5 September, 2019 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});